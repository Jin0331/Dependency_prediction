{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea56ff88-91cf-46a6-a8db-f24f13ef8e5a",
   "metadata": {},
   "source": [
    "* **Custom module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5cbba0-e22a-4a7f-ab97-09dc7665a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14f8f5-28be-4679-b446-5d8382a25f15",
   "metadata": {},
   "source": [
    "* **Paper module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc4f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras.layers import Dense, Merge\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3892fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wmbio/WORK/gitworking/Dependency_prediction/prediction/src\n",
      "/home/wmbio/WORK/gitworking/Dependency_prediction\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/home/wmbio/WORK/gitworking/Dependency_prediction/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7afb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    gene_names = []\n",
    "#     data_labels = []\n",
    "    lines = open(filename).readlines()\n",
    "    sample_names = lines[0].replace('\\n', '').split('\\t')[1:]\n",
    "    dx = 1\n",
    "\n",
    "    for line in tqdm(lines[dx:], leave=True):\n",
    "        values = line.replace('\\n', '').split('\\t')\n",
    "        gene = str.upper(values[0])\n",
    "        gene_names.append(gene)\n",
    "        data.append(values[1:])\n",
    "    data = np.array(data, dtype='float32')\n",
    "    data = np.transpose(data)\n",
    "\n",
    "    return data, sample_names, gene_names\n",
    "\n",
    "def exp_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_exp = Sequential()\n",
    "        model_exp.add(Dense(500, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(200, input_dim=500, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(50, input_dim=200, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_exp.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=100, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_exp.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final  \n",
    "\n",
    "def exp_model_paper():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_exp = models.Sequential()\n",
    "        model_exp.add(Dense(output_dim=500, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(output_dim=200, input_dim=500, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(output_dim=50, input_dim=200, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_gene = models.Sequential()\n",
    "        model_gene.add(Dense(output_dim=1000, input_dim=data_fprint.shape[1], activation=activation_func, init=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(output_dim=100, input_dim=1000, activation=activation_func, init=init, trainable=True))\n",
    "        model_gene.add(Dense(output_dim=50, input_dim=100, activation=activation_func, init=init, trainable=True))\n",
    "\n",
    "        model_final = models.Sequential()\n",
    "        model_final.add(Merge([model_exp, model_gene], mode='concat'))\n",
    "        model_final.add(Dense(output_dim=dense_layer_dim, input_dim=100, activation=activation_func, init=init))\n",
    "        model_final.add(Dense(output_dim=dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, init=init))\n",
    "        model_final.add(Dense(output_dim=1, input_dim=dense_layer_dim, activation=activation_func2, init=init))\n",
    "        \n",
    "        return model_final  \n",
    "    \n",
    "\n",
    "class generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_mut, x_exp, x_cna, x_meth, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_exp, self.x_cna, self.x_meth, self.x_fprint, self.y_dep = x_mut, x_exp, x_cna, x_meth, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.y_dep) - 1) // self.bs + 1\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_exp[start:end], self.x_cna[start:end], self.x_meth[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "\n",
    "class generator3(generator):\n",
    "    def __init__(self, x_mut, x_exp, x_cna, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_exp, self.x_cna, self.x_fprint, self.y_dep = x_mut, x_exp, x_cna, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_exp[start:end], self.x_cna[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "    \n",
    "class generator2(generator):\n",
    "    def __init__(self, x_mut, x_exp, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_exp, self.x_fprint, self.y_dep = x_mut, x_exp, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_exp[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "\n",
    "class generator1(generator):\n",
    "    def __init__(self, x_mut, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_fprint, self.y_dep = x_mut, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "    \n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "    \n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def model_train_vis(history):\n",
    "    coeff = history.history['coeff_determination']\n",
    "    val_coeff = history.history['val_coeff_determination']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(coeff))\n",
    "    \n",
    "    plt.plot(epochs, coeff, 'bo', label='Training')\n",
    "    plt.plot(epochs, val_coeff, 'b', label='Validation')\n",
    "    plt.title('Training and validation Coeff determination(R-squared)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation')\n",
    "    plt.title('Training and validation loss(MSE)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a52ce5",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "# with open('prediction/data/ccl_complete_data_28CCL_1298DepOI_36344samples_demo.pickle', 'rb') as f:\n",
    "# with open('data/ccl_complete_data_278CCL_1298DepOI_360844samples.pickle', 'rb') as f:\n",
    "#     data_mut, data_exp, data_cna, data_meth, data_dep, data_fprint = pickle.load(f)\n",
    "# This pickle file is for DEMO ONLY (containing 28 CCLs x 1298 DepOIs = 36344 samples)!\n",
    "# First 1298 samples correspond to 1298 DepOIs of the first CCL, and so on.\n",
    "# For the complete data used in the paper (278 CCLs x 1298 DepOIs = 360844 samples),\n",
    "# please substitute by 'ccl_complete_data_278CCL_1298DepOI_360844samples.pickle',\n",
    "# to which a link can be found in README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce458094",
   "metadata": {},
   "source": [
    "## **Data Load & Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ab4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/home/wmbio/WORK/gitworking/Dependency_prediction/preprocessing/TRAIN/2022-07-27/'\n",
    "TEMP_PATH = \"prediction/train_preprocessing/\"\n",
    "SAVE_PATH = \"prediction/custom_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e2d6bc-ca60-4677-ba0e-24f1a883fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction/data/ccl_complete_data_28CCL_1298DepOI_36344samples_demo.pickle', 'rb') as f:\n",
    "    data_mut, data_exp, data_cna, data_meth, data_dep, data_fprint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40cd71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Build Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18fa6f",
   "metadata": {},
   "source": [
    "* **Pretrained Model load - TCGA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971409bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Datasets successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "premodel_mut = pickle.load(open('prediction/data/premodel_tcga_mut_1000_100_50.pickle', 'rb'))\n",
    "premodel_exp = pickle.load(open('prediction/data/premodel_tcga_exp_500_200_50.pickle', 'rb'))\n",
    "premodel_cna = pickle.load(open('prediction/data/premodel_tcga_cna_500_200_50.pickle', 'rb'))\n",
    "premodel_meth = pickle.load(open('prediction/data/premodel_tcga_meth_500_200_50.pickle', 'rb'))\n",
    "print(\"\\n\\nDatasets successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2250bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = 'relu' # for all middle layers\n",
    "activation_func2 = 'linear' # for output layer to output unbounded gene-effect scores\n",
    "init = 'he_uniform'\n",
    "dense_layer_dim = 250\n",
    "batch_size = 500\n",
    "num_epoch = 100\n",
    "num_DepOI = 1298 # 1298 DepOIs as defined in our paper\n",
    "num_ccl = int(data_mut.shape[0]/num_DepOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ea880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training/validation on 32450 samples (25 CCLs x 1298 DepOIs) and testing on 3894 samples (3 CCLs x 1298 DepOIs).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_rand = np.random.permutation(num_ccl)\n",
    "id_cell_train = id_rand[np.arange(0, round(num_ccl*0.9))]\n",
    "id_cell_test = id_rand[np.arange(round(num_ccl*0.9), num_ccl)]\n",
    "\n",
    "# prepare sample indices (selected CCLs x 1298 DepOIs)\n",
    "id_train = np.arange(0, 1298) + id_cell_train[0]*1298\n",
    "for y in id_cell_train:\n",
    "    id_train = np.union1d(id_train, np.arange(0, 1298) + y*1298)\n",
    "id_test = np.arange(0, 1298) + id_cell_test[0] * 1298\n",
    "for y in id_cell_test:\n",
    "    id_test = np.union1d(id_test, np.arange(0, 1298) + y*1298)\n",
    "print(\"\\n\\nTraining/validation on %d samples (%d CCLs x %d DepOIs) and testing on %d samples (%d CCLs x %d DepOIs).\\n\\n\" % (\n",
    "    len(id_train), len(id_cell_train), num_DepOI, len(id_test), len(id_cell_test), num_DepOI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858abcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model_final, show_shapes=True,  show_dtype=True, to_file='model_custom.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3accc4e",
   "metadata": {},
   "source": [
    "## **Fit & Evaluation Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cb8bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **(1) Full Model 4-Omics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(data_mut[id_train], data_exp[id_train], data_cna[id_train], data_meth[id_train], \n",
    "                                    data_fprint[id_train], data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e13dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator(data_mut[id_test], data_exp[id_test], data_cna[id_test], data_meth[id_test], \n",
    "                                    data_fprint[id_test], data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ffa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_full_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca3d06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **(2) Expression-Mutation-CNA Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7aeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator3(data_mut[id_train], data_exp[id_train], data_cna[id_train], \n",
    "                                    data_fprint[id_train], data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator3(data_mut[id_test], data_exp[id_test], data_cna[id_test],\n",
    "                                    data_fprint[id_test], data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefed8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_mut_cna_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_exp_cna_0725\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046378bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **(3) Expression-Mutation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69827f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator2(data_mut[id_train], data_exp[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496568f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator2(data_mut[id_test], data_exp[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_mut_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67109c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_exp_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce33018",
   "metadata": {},
   "source": [
    "### **(4) Expression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15be141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator1(data_exp[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8d6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator1(data_exp[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ff4774-4ebc-4586-8dfc-b26ccc1db1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:33:57.556212: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-28 12:33:57.556752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-28 12:33:57.595439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.595965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.807GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-07-28 12:33:57.595975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-28 12:33:57.596975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-28 12:33:57.597010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-28 12:33:57.597917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-28 12:33:57.598073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-28 12:33:57.598929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-28 12:33:57.599282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-28 12:33:57.600988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-28 12:33:57.601047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.601483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.601848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-28 12:33:57.602374: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 12:33:57.602880: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-28 12:33:57.602931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.603291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.807GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-07-28 12:33:57.603298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-28 12:33:57.603308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-28 12:33:57.603313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-28 12:33:57.603317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-28 12:33:57.603321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-28 12:33:57.603325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-28 12:33:57.603330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-28 12:33:57.603334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-28 12:33:57.603355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.603581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:33:57.603791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-28 12:33:57.603805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-28 12:36:06.072054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-28 12:36:06.072075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-07-28 12:36:06.072078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-07-28 12:36:06.072229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:36:06.072648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:36:06.072995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 12:36:06.073301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11078 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2022-07-28 12:36:06.137295: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-28 12:36:06.157367: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3187200000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 2s 22ms/step - loss: 2.2906 - coeff_determination: -10.1151 - val_loss: 0.1290 - val_coeff_determination: 0.3059\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1224 - coeff_determination: 0.3554 - val_loss: 0.0518 - val_coeff_determination: 0.7148\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0493 - coeff_determination: 0.7328 - val_loss: 0.0475 - val_coeff_determination: 0.7365\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0447 - coeff_determination: 0.7579 - val_loss: 0.0467 - val_coeff_determination: 0.7418\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0415 - coeff_determination: 0.7729 - val_loss: 0.0478 - val_coeff_determination: 0.7380\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0442 - coeff_determination: 0.7667 - val_loss: 0.0477 - val_coeff_determination: 0.7371\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 1s 21ms/step - loss: 0.0420 - coeff_determination: 0.7747 - val_loss: 0.0473 - val_coeff_determination: 0.7379\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0411 - coeff_determination: 0.7776 - val_loss: 0.0508 - val_coeff_determination: 0.7158\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0412 - coeff_determination: 0.7800 - val_loss: 0.0449 - val_coeff_determination: 0.7503\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0406 - coeff_determination: 0.7843 - val_loss: 0.0456 - val_coeff_determination: 0.7442\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0365 - coeff_determination: 0.8015 - val_loss: 0.0506 - val_coeff_determination: 0.7151\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0354 - coeff_determination: 0.8074 - val_loss: 0.0410 - val_coeff_determination: 0.7757\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0358 - coeff_determination: 0.8027 - val_loss: 0.0471 - val_coeff_determination: 0.7360\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0380 - coeff_determination: 0.7915 - val_loss: 0.0457 - val_coeff_determination: 0.7448\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 1s 20ms/step - loss: 0.0355 - coeff_determination: 0.8026 - val_loss: 0.0661 - val_coeff_determination: 0.6254\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0406 - coeff_determination: 0.7788 - val_loss: 0.0445 - val_coeff_determination: 0.7538\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0362 - coeff_determination: 0.8006 - val_loss: 0.0514 - val_coeff_determination: 0.7094\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = exp_model()\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "    history = model.fit(train_generator, \n",
    "                        validation_data=test_generator, \n",
    "                        epochs=num_epoch, verbose=1,         \n",
    "                        callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0151be1-3e20-4033-8fe9-eced94b38e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Full DeepDEP model saved in prediction/custom_model/model_paper_exp_0727_keras2.h5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAVE_NAME = \"model_paper_exp_0727_keras2\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94342111-996a-4c8e-80a0-8b00df7789fe",
   "metadata": {},
   "source": [
    "* **Keras 1.x**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c5b37-c88b-4507-8271-e31365015445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f680b-baad-495a-87d7-1113c316ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit([data_exp[id_train], data_fprint[id_train]], data_dep[id_train], nb_epoch=num_epoch,\n",
    "                validation_split=1/9, batch_size=batch_size, shuffle=True, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e680d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_paper_exp_0727\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab8dd7-cefd-43e2-918a-713683e2a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfebb8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **(5) Mutation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator1(data_mut[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae7ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator1(data_mut[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74168a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mut_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729abb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae7d88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **(6) CNA Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator1(data_cna[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb67039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator1(data_cna[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3024140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mut_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5298da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_cna_0726\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd78b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepDEP",
   "language": "python",
   "name": "deepdep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
