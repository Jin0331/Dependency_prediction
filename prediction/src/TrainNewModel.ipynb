{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/home/wmbio/WORK/gitworking/DeepDEP/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    gene_names = []\n",
    "#     data_labels = []\n",
    "    lines = open(filename).readlines()\n",
    "    sample_names = lines[0].replace('\\n', '').split('\\t')[1:]\n",
    "    dx = 1\n",
    "\n",
    "    for line in tqdm(lines[dx:], leave=True):\n",
    "        values = line.replace('\\n', '').split('\\t')\n",
    "        gene = str.upper(values[0])\n",
    "        gene_names.append(gene)\n",
    "        data.append(values[1:])\n",
    "    data = np.array(data, dtype='float32')\n",
    "    data = np.transpose(data)\n",
    "\n",
    "    return data, sample_names, gene_names\n",
    "\n",
    "def full_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_mut = Sequential()\n",
    "        model_mut.add(Dense(1000, input_dim=premodel_mut[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_mut[0], trainable=True))\n",
    "        model_mut.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_mut[1],\n",
    "                            trainable=True))\n",
    "        model_mut.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_mut[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_exp = Sequential()\n",
    "        model_exp.add(Dense(1000, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_cna = Sequential()\n",
    "        model_cna.add(Dense(1000, input_dim=premodel_cna[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_cna[0], trainable=True))\n",
    "        model_cna.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_cna[1],\n",
    "                            trainable=True))\n",
    "        model_cna.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_cna[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_meth = Sequential()\n",
    "        model_meth.add(Dense(1000, input_dim=premodel_meth[0][0].shape[0], activation=activation_func,\n",
    "                             weights=premodel_meth[0], trainable=True))\n",
    "        model_meth.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_meth[1],\n",
    "                             trainable=True))\n",
    "        model_meth.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_meth[2],\n",
    "                             trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_mut.output, model_exp.output, \n",
    "                              model_cna.output, model_meth.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=250, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_mut.input, model_exp.input, model_cna.input, model_meth.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final\n",
    "\n",
    "def exp_mut_cna_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_mut = Sequential()\n",
    "        model_mut.add(Dense(1000, input_dim=premodel_mut[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_mut[0], trainable=True))\n",
    "        model_mut.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_mut[1],\n",
    "                            trainable=True))\n",
    "        model_mut.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_mut[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_exp = Sequential()\n",
    "        model_exp.add(Dense(1000, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_cna = Sequential()\n",
    "        model_cna.add(Dense(1000, input_dim=premodel_cna[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_cna[0], trainable=True))\n",
    "        model_cna.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_cna[1],\n",
    "                            trainable=True))\n",
    "        model_cna.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_cna[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_mut.output, model_exp.output, \n",
    "                              model_cna.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=200, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_mut.input, model_exp.input, model_cna.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final\n",
    "    \n",
    "    \n",
    "def exp_mut_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_mut = Sequential()\n",
    "        model_mut.add(Dense(1000, input_dim=premodel_mut[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_mut[0], trainable=True))\n",
    "        model_mut.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_mut[1],\n",
    "                            trainable=True))\n",
    "        model_mut.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_mut[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        model_exp = Sequential()\n",
    "        model_exp.add(Dense(1000, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_mut.output, model_exp.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=150, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_mut.input, model_exp.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final    \n",
    "\n",
    "def exp_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_exp = Sequential()\n",
    "        model_exp.add(Dense(1000, input_dim=premodel_exp[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_exp[0], trainable=True))\n",
    "        model_exp.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_exp[1],\n",
    "                            trainable=True))\n",
    "        model_exp.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_exp[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_exp.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=100, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_exp.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final  \n",
    "    \n",
    "def mut_model():\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_mut = Sequential()\n",
    "        model_mut.add(Dense(1000, input_dim=premodel_mut[0][0].shape[0], activation=activation_func,\n",
    "                            weights=premodel_mut[0], trainable=True))\n",
    "        model_mut.add(Dense(100, input_dim=1000, activation=activation_func, weights=premodel_mut[1],\n",
    "                            trainable=True))\n",
    "        model_mut.add(Dense(50, input_dim=100, activation=activation_func, weights=premodel_mut[2],\n",
    "                            trainable=True))\n",
    "\n",
    "        # subnetwork of gene fingerprints\n",
    "        model_gene = Sequential()\n",
    "        model_gene.add(Dense(1000, input_dim=data_fprint.shape[1], activation=activation_func, kernel_initializer=init,\n",
    "                             trainable=True))\n",
    "        model_gene.add(Dense(100, input_dim=1000, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "        model_gene.add(Dense(50, input_dim=100, activation=activation_func, kernel_initializer=init, trainable=True))\n",
    "\n",
    "        conc = Concatenate()([model_mut.output, model_gene.output])\n",
    "\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=100, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(conc)\n",
    "        model_pre = Dense(dense_layer_dim, input_dim=dense_layer_dim, activation=activation_func, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "        model_pre = Dense(1, input_dim=dense_layer_dim, activation=activation_func2, kernel_initializer=init,\n",
    "                              trainable=True)(model_pre)\n",
    "\n",
    "        model_final = Model([model_mut.input, model_gene.input], model_pre)\n",
    "        \n",
    "        return model_final  \n",
    "\n",
    "class generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_mut, x_exp, x_cna, x_meth, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_exp, self.x_cna, self.x_meth, self.x_fprint, self.y_dep = x_mut, x_exp, x_cna, x_meth, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.y_dep) - 1) // self.bs + 1\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_exp[start:end], self.x_cna[start:end], self.x_meth[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "\n",
    "class generator2(generator):\n",
    "    def __init__(self, x_mut, x_exp, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_exp, self.x_fprint, self.y_dep = x_mut, x_exp, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_exp[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "\n",
    "class generator1(generator):\n",
    "    def __init__(self, x_mut, x_fprint, y_dep, batch_size):\n",
    "        self.x_mut, self.x_fprint, self.y_dep = x_mut, x_fprint, y_dep\n",
    "        self.bs = batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start, end = idx * self.bs, (idx+1) * self.bs\n",
    "        return (self.x_mut[start:end], self.x_fprint[start:end]), self.y_dep[start:end]\n",
    "    \n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "    \n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def model_train_vis(history):\n",
    "    coeff = history.history['coeff_determination']\n",
    "    val_coeff = history.history['val_coeff_determination']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(coeff))\n",
    "    \n",
    "    plt.plot(epochs, coeff, 'bo', label='Training')\n",
    "    plt.plot(epochs, val_coeff, 'b', label='Validation')\n",
    "    plt.title('Training and validation Coeff determination(R-squared)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation')\n",
    "    plt.title('Training and validation loss(MSE)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "# with open('prediction/data/ccl_complete_data_28CCL_1298DepOI_36344samples_demo.pickle', 'rb') as f:\n",
    "# with open('data/ccl_complete_data_278CCL_1298DepOI_360844samples.pickle', 'rb') as f:\n",
    "#     data_mut, data_exp, data_cna, data_meth, data_dep, data_fprint = pickle.load(f)\n",
    "# This pickle file is for DEMO ONLY (containing 28 CCLs x 1298 DepOIs = 36344 samples)!\n",
    "# First 1298 samples correspond to 1298 DepOIs of the first CCL, and so on.\n",
    "# For the complete data used in the paper (278 CCLs x 1298 DepOIs = 360844 samples),\n",
    "# please substitute by 'ccl_complete_data_278CCL_1298DepOI_360844samples.pickle',\n",
    "# to which a link can be found in README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Load & Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/home/wmbio/WORK/gitworking/DeepDEP/preprocessing/DATA/2022-07-13/\"\n",
    "TEMP_PATH = \"prediction/train_preprocessing/\"\n",
    "SAVE_PATH = \"prediction/custom_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"prediction/data/ccl_complete_data_501CCL_1298DepOI_614727samples_custom.npz\") is False:\n",
    "    # load TCGA mutation data, substitute here with other genomics\n",
    "    data_exp, sample_names_exp, property_names_exp = load_data(TRAIN_PATH + \"train_exp_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_exp_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_exp_training.npy', data_exp)\n",
    "\n",
    "    data_mut, sample_names_mut, property_names_mut = load_data(TRAIN_PATH + \"train_mut_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_mut_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_mut_training.npy', data_mut)\n",
    "\n",
    "    data_cna, sample_names_cna, property_names_cna = load_data(TRAIN_PATH + \"train_cna_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_cna_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_cna_training.npy', data_cna)\n",
    "\n",
    "    data_meth, sample_names_meth, property_names_meth = load_data(TRAIN_PATH + \"train_meth_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_meth_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_meth_training.npy', data_meth)\n",
    "\n",
    "    data_dep, sample_names_dep, property_names_dep = load_data(TRAIN_PATH + \"train_DepScore_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_DepScore_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_DepScore_training.npy', data_dep)\n",
    "\n",
    "    data_fprint, sample_names_fprint, property_names_fprint = load_data(TRAIN_PATH + \"train_fingerprint_training.txt\")\n",
    "    if exists(TEMP_PATH + \"train_fingerprint_training.npy\") is False:\n",
    "        np.save(TEMP_PATH + 'train_fingerprint_training.npy', data_fprint)\n",
    "\n",
    "    np.savez_compressed(\"prediction/data/ccl_complete_data_501CCL_1298DepOI_614727samples_custom.npz\", \n",
    "                        data_exp=data_exp, data_mut=data_mut, data_cna=data_cna, data_meth=data_meth,\n",
    "                        data_dep=data_dep, data_fprint=data_fprint)\n",
    "else :\n",
    "    data = np.load(\"prediction/data/ccl_complete_data_501CCL_1298DepOI_614727samples_custom.npz\")\n",
    "    data_exp = data['data_exp']\n",
    "    data_mut = data['data_mut']\n",
    "    data_cna = data['data_cna']\n",
    "    data_meth = data['data_meth']\n",
    "    data_fprint = data['data_fprint']\n",
    "    data_dep = data['data_dep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Build Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Pretrained Model load - TCGA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autoencoders of each genomics that were pre-trained using 8238 TCGA samples\n",
    "# New autoencoders can be pretrained using PretrainAE.py\n",
    "premodel_mut = pickle.load(open(SAVE_PATH + 'pretrained/premodel_tcga_custom_mut_1000_100_50.pickle', 'rb'))\n",
    "premodel_exp = pickle.load(open(SAVE_PATH + 'pretrained/premodel_tcga_custom_exp_1000_100_50.pickle', 'rb'))\n",
    "premodel_cna = pickle.load(open(SAVE_PATH + 'pretrained/premodel_tcga_custom_cna_1000_100_50.pickle', 'rb'))\n",
    "premodel_meth = pickle.load(open(SAVE_PATH + 'pretrained/premodel_tcga_custom_meth_1000_100_50.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = 'relu' # for all middle layers\n",
    "activation_func2 = 'linear' # for output layer to output unbounded gene-effect scores\n",
    "init = 'he_uniform'\n",
    "dense_layer_dim = 250\n",
    "batch_size = 64\n",
    "num_epoch = 100\n",
    "num_DepOI = 1227 # 1298 DepOIs as defined in our paper, custom 1227\n",
    "num_ccl = int(data_mut.shape[0]/num_DepOI)\n",
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% CCLs for training/validation, and 20% for testing\n",
    "id_rand = np.random.permutation(num_ccl)\n",
    "id_cell_train = id_rand[np.arange(0, round(num_ccl * split_ratio))]\n",
    "id_cell_test = id_rand[np.arange(round(num_ccl * split_ratio), num_ccl)]\n",
    "id_train = np.arange(0, num_DepOI) + id_cell_train[0]*num_DepOI\n",
    "for y in id_cell_train:\n",
    "    id_train = np.union1d(id_train, np.arange(0, num_DepOI) + y*num_DepOI)\n",
    "id_test = np.arange(0, num_DepOI) + id_cell_test[0] * num_DepOI\n",
    "for y in id_cell_test:\n",
    "    id_test = np.union1d(id_test, np.arange(0, num_DepOI) + y*num_DepOI)\n",
    "print(\"\\n\\nTraining/validation on %d samples (%d CCLs x %d DepOIs) and testing on %d samples (%d CCLs x %d DepOIs).\\n\\n\" % (\n",
    "    len(id_train), len(id_cell_train), num_DepOI, len(id_test), len(id_cell_test), num_DepOI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model_final, show_shapes=True,  show_dtype=True, to_file='model_custom.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit & Evaluation Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) Full Model 4-Omics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(data_mut[id_train], data_exp[id_train], data_cna[id_train], data_meth[id_train], \n",
    "                                    data_fprint[id_train], data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator(data_mut[id_test], data_exp[id_test], data_cna[id_test], data_meth[id_test], \n",
    "                                    data_fprint[id_test], data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_full_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(2) Expression-Mutation-CNA Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(data_mut[id_train], data_exp[id_train], data_cna[id_train], \n",
    "                                    data_fprint[id_train], data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator(data_mut[id_test], data_exp[id_test], data_cna[id_test],\n",
    "                                    data_fprint[id_test], data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_exp_cna_0725\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) Expression-Mutation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator2(data_mut[id_train], data_exp[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator2(data_mut[id_test], data_exp[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_mut_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_exp_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) Expression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator1(data_exp[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator1(data_exp[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_exp_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4) Mutation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator1(data_mut[id_train], data_fprint[id_train],\n",
    "                            data_dep[id_train], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator1(data_mut[id_test], data_fprint[id_test],\n",
    "                           data_dep[id_test], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mut_model()\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=num_epoch, verbose=1,         \n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_vis(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = \"model_custom_mut_0720\"\n",
    "model.save(SAVE_PATH + SAVE_NAME + \".h5\")\n",
    "print(\"\\n\\nFull DeepDEP model saved in %s\\n\\n\" % (SAVE_PATH + SAVE_NAME + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepdep",
   "language": "python",
   "name": "deepdep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
